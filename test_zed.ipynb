{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7047bffe",
   "metadata": {},
   "source": [
    "## I just use the file to test and play with the camera.\n",
    "## DO NOT USE THIS FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3f45216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyQt5\n",
    "%matplotlib qt\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pyzed.sl as sl\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b78d394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MediaPipe Utilities and Model\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "hand_model = mp_hands.Hands(min_detection_confidence=0.6, min_tracking_confidence=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87f442cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ZED object\n",
    "zed = sl.Camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "950f3b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Camera Initial Parameters\n",
    "init = sl.InitParameters()\n",
    "init.camera_resolution = sl.RESOLUTION.HD720\n",
    "init.coordinate_units = sl.UNIT.METER\n",
    "init.depth_maximum_distance = 3\n",
    "init.depth_minimum_distance = 0.1\n",
    "init.depth_mode = sl.DEPTH_MODE.NEURAL\n",
    "init.camera_fps = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c803ae39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "# Open the ZED Camera\n",
    "zed.open(init)\n",
    "print(zed.get_camera_information().camera_configuration.resolution.width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fc221ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Runtime Parameters\n",
    "runtime = sl.RuntimeParameters()\n",
    "runtime.enable_fill_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e616dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Camera Readings\n",
    "image = sl.Mat()\n",
    "depth = sl.Mat()\n",
    "point_cloud = sl.Mat()\n",
    "confidence_map = sl.Mat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8de51f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Camera Calibration Parameters\n",
    "fx = zed.get_camera_information().camera_configuration.calibration_parameters.left_cam.fx\n",
    "fy = zed.get_camera_information().camera_configuration.calibration_parameters.left_cam.fy\n",
    "cx = zed.get_camera_information().camera_configuration.calibration_parameters.left_cam.cx\n",
    "cy = zed.get_camera_information().camera_configuration.calibration_parameters.left_cam.cy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c34892d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize Visualization Using Matplot\n",
    "fig = plt.figure()\n",
    "\n",
    "# enable interactive mode\n",
    "plt.ion() \n",
    "ax = fig.add_subplot(111, projection = '3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0902957d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    clear_output(wait=False)\n",
    "    err = zed.grab(runtime)\n",
    "    if err == sl.ERROR_CODE.SUCCESS:\n",
    "        \n",
    "        # Get Start Time of Each Loop for Calculating FPS\n",
    "        time0 = time.time()\n",
    "        \n",
    "        # Get An Image From Left \n",
    "        zed.retrieve_image(image, sl.VIEW.LEFT)\n",
    "        \n",
    "        # Get Depth Data\n",
    "        zed.retrieve_measure(depth, sl.MEASURE.DEPTH)\n",
    "        \n",
    "        # Get Point Cloud Data\n",
    "        zed.retrieve_measure(point_cloud, sl.MEASURE.XYZRGBA)\n",
    "        \n",
    "        # Convert the Image So That MediaPipe Can Process\n",
    "        img = image.get_data()\n",
    "        img.flags.writeable = False\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Send image to MediaPipe model and get results\n",
    "        results = hand_model.process(img)\n",
    "        \n",
    "        # And Then Convert Back for OpenCV to Display\n",
    "        img.flags.writeable = True\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # get Number of Hands\n",
    "        num_hands = 0\n",
    "        \n",
    "        # get image shape\n",
    "        h, w, _ = img.shape\n",
    "        \n",
    "        # Play with the Hand Landmarks\n",
    "        if results.multi_hand_landmarks:\n",
    "            ax.clear()\n",
    "            \n",
    "            for num, landmarks in enumerate(results.multi_hand_landmarks):\n",
    "                \n",
    "                left_data = []\n",
    "                right_data = []\n",
    "                \n",
    "                # Get the number of hands\n",
    "                num_hands = 1 + num\n",
    "                \n",
    "                # Get handedness (need to flip later)\n",
    "                handedness = results.multi_handedness[results.multi_hand_landmarks.index(landmarks)].classification[0].label\n",
    "                \n",
    "                for id, landmark in enumerate(landmarks.landmark):\n",
    "                    \n",
    "                    # wrist's index is 0\n",
    "                    if id == 0:\n",
    "                        \n",
    "                        # get wrist landmark coordinates\n",
    "                        wrist_landmark_coordinates = [landmark.x, landmark.y, landmark.z]\n",
    "                        \n",
    "                        print(landmark.z)\n",
    "                        # convert landmark to pixels\n",
    "                        X, Y = int(landmark.x * w), int(landmark.y * h)\n",
    "                        \n",
    "                        # get point cloud values for this wrist pixel\n",
    "                        if X > 0 and Y > 0:\n",
    "                            err, point_cloud_value = point_cloud.get_value(X, Y)\n",
    "                            wrist_position = [point_cloud_value[0],\n",
    "                                              point_cloud_value[1],\n",
    "                                              point_cloud_value[2]]\n",
    "                    if id == 8:\n",
    "                        print(landmark.z)\n",
    "                        \n",
    "                    # calculate more accurate positions\n",
    "                    x_3d = wrist_position[0] + \\\n",
    "                           (landmark.x*w - wrist_landmark_coordinates[0]*w) * \\\n",
    "                           wrist_position[2]/fx\n",
    "                            \n",
    "                    y_3d = wrist_position[1] + \\\n",
    "                           (landmark.y*h - wrist_landmark_coordinates[1]*h) * \\\n",
    "                           wrist_position[2]/fy\n",
    "                            \n",
    "                    z_3d = wrist_position[2] + \\\n",
    "                           (landmark.z - wrist_landmark_coordinates[2])/ \\\n",
    "                           wrist_position[2]\n",
    "                    \n",
    "                    # this is the calculated 3d position of each landmark (joint)\n",
    "                    hand_landmarks_3d = [x_3d, y_3d, z_3d]\n",
    "                    \n",
    "                    # save 3d position of each joint to different hands\n",
    "                    if handedness == \"Right\":\n",
    "                        left_data.append(hand_landmarks_3d)\n",
    "                    elif handedness == \"Left\":\n",
    "                        right_data.append(hand_landmarks_3d)\n",
    "                    \n",
    "                # convert to numpy\n",
    "                left_data = np.array(left_data)\n",
    "                right_data = np.array(right_data)\n",
    "                    \n",
    "                # Flipped detection, switch left and right in image, \n",
    "                # and plot in Matplot\n",
    "                if handedness == \"Right\":\n",
    "                    \n",
    "                    cv2.putText(img, \"Left\", (X, Y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    \n",
    "                    xlim=(-0.5, 0.5)\n",
    "                    ylim=(-0.5, 0.5)\n",
    "                    zlim=(0.2, 1.0)\n",
    "                    ax.set_xlim3d(xlim)\n",
    "                    ax.set_ylim3d(ylim)\n",
    "                    ax.set_zlim3d(zlim)\n",
    "                    ax.set_xlabel('x')\n",
    "                    ax.set_ylabel('y')\n",
    "                    ax.set_zlabel('z')\n",
    "                    ax.scatter3D(left_data[0, 0],\n",
    "                                 left_data[0, 1],\n",
    "                                 left_data[0, 2], color = 'b')\n",
    "                    plt.draw()\n",
    "                    plt.pause(0.0001)\n",
    "                \n",
    "                elif handedness == \"Left\":\n",
    "                    \n",
    "                    cv2.putText(img, \"Right\", (X, Y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "                    \n",
    "                    xlim=(-0.5, 0.5)\n",
    "                    ylim=(-0.5, 0.5)\n",
    "                    zlim=(0.2, 1.0)\n",
    "                    ax.set_xlim3d(xlim)\n",
    "                    ax.set_ylim3d(ylim)\n",
    "                    ax.set_zlim3d(zlim)\n",
    "                    ax.set_xlabel('x')\n",
    "                    ax.set_ylabel('y')\n",
    "                    ax.set_zlabel('z')\n",
    "                    ax.scatter3D(right_data[0, 0],\n",
    "                                 right_data[0, 1],\n",
    "                                 right_data[0, 2], color = 'r')\n",
    "                    plt.draw()\n",
    "                    plt.pause(0.0001)\n",
    "                    \n",
    "                mp_drawing.draw_landmarks(img, landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                \n",
    "        # Print Number of Hands\n",
    "        print(num_hands)\n",
    "        \n",
    "        # Calculate FPS        \n",
    "        time1 = time.time()\n",
    "        if (time1-time0) > 0:\n",
    "            frames_per_sec = 1.0/(time1 - time0)\n",
    "            cv2.putText(img, 'FPS: {}'.format(int(frames_per_sec)), \n",
    "                        (10, 30),cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 3)\n",
    "        \n",
    "        # Use OpenCV to display the Image\n",
    "        # img = cv2.flip(img, 1)\n",
    "        cv2.imshow(\"test\", img)\n",
    "        \n",
    "\n",
    "    # Press Q to Stop\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be4bf6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2041457037062253"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmark.z/wrist_position[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78988319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3160422146320343"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrist_position[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0995a3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7858258388457267"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((h/fy)**2 + (w/fx)**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8558ceec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8400660748941304"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((fy/h)**2 + (fx/w)**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8800f289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13 not in [5, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfeca03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
